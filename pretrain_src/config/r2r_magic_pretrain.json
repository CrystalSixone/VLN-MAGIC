{
    "model_config": "",
    "teacher_checkpoint": "",
    "student_checkpoint": "",
    "output_dir": "",
    "mrc_mask_prob": 0.15,
    "max_txt_len": 200,
    "train_batch_size": 48,
    "val_batch_size": 48,
    "gradient_accumulation_steps": 1,
    "learning_rate": 5e-5,
    "valid_steps": 1000,
    "log_steps": 1500,
    "num_train_steps": 200000,
    "optim": "adamw",
    "betas": [
        0.9,
        0.98
    ],
    "dropout": 0.1,
    "weight_decay": 0.01,
    "grad_norm": 5.0,
    "warmup_steps": 10000,
    "seed": 0,
    "fp16": false,
    "n_workers": 8,
    "pin_mem": true,
    "init_pretrained": "meter",

    "correct_heading": false,

    "train_datasets": {
        "R2R": {
            "name": "R2R",
            "train_traj_files": ["../datasets/R2R/annotations/pretrain_map/R2R_train_enc.jsonl",
                                 "../datasets/R2R/annotations/pretrain_map/R2R_prevalent_aug_train_enc.jsonl"],
            "val_seen_traj_files": ["../datasets/R2R/annotations/pretrain_map/R2R_val_seen_enc.jsonl"],
            "val_unseen_traj_files": ["../datasets/R2R/annotations/pretrain_map/R2R_val_unseen_enc.jsonl"],
            "train_roberta_files": ["../datasets/R2R/annotations/pretrain_map/R2R_train_roberta_enc.jsonl",
                                 "../datasets/R2R/annotations/pretrain_map/R2R_prevalent_aug_train_roberta_enc.jsonl"],
            "val_seen_roberta_files": ["../datasets/R2R/annotations/pretrain_map/R2R_val_seen_roberta_enc.jsonl"],
            "val_unseen_roberta_files": ["../datasets/R2R/annotations/pretrain_map/R2R_val_unseen_roberta_enc.jsonl"],
            "connectivity_dir": "../datasets/R2R/connectivity",
            "clip768_img_ft_file": "../datasets/R2R/features/CLIP-ViT-B-16-views.hdf5",
            "cat_file": "../datasets/R2R/annotations/category_mapping.tsv",
            "img_zdict_file": "../datasets/R2R/features/image_z_dict_clip_50.tsv",
            "instr_zdict_file": "../datasets/R2R/features/instr_z_dict2.tsv",
            "aug_img_file": "../datasets/EnvEdit/hamt_features/CLIP-ViT-B-16-views-st-samefilter.hdf5",
            "tasks": [
                "mlm",
                "sap",
                "cfp"
            ],
            "mix_ratio": [
                1,
                1,
                1
            ]
        }
    },

    "kdl":{
        "train_teacher": false,
        "knowledge_distillation": true,
        "kd_alpha": 0.5,
        "kd_temperature": 2,
        "kd_loss": "mse",
        "kdl_attn_loss": "mse",
        "kdl_logits_loss": "kd",
        "kdl_adaptive_ability_weight": true,
        "kdl_adaptive_ability_weight_type": "RW",
        "rw_temp": 4, 
        "teacher_sample_hard_mining": true,
        "t_sample_preprocess": "exp",
        "t_sample_preprocess_exp_decay": 0.7,
        "kdl_tasks":[
            "txt",
            "img",
            "local",
            "global",
            "predict"
        ],
        "kdl_task_types":[
            "emb",
            "attn"
        ]
    }
}
